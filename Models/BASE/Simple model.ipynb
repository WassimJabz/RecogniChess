{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b950cda7",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144fa7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now load the dependencies\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# If VSCode doesn't pick up this import, see answer here: \n",
    "# https://stackoverflow.com/questions/65252074/import-path-to-own-script-could-not-be-resolved-pylance-reportmissingimports\n",
    "import sys\n",
    "sys.path.append(\"../../Datasets/\")\n",
    "from Custom_Dataset import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6211a13b",
   "metadata": {},
   "source": [
    "We can start by setting a seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356ddda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16bfa0181d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b93703ce",
   "metadata": {},
   "source": [
    "# Hyperparameter choices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b259e4e1",
   "metadata": {},
   "source": [
    "We create a cell to hold the hyperparameters of the model to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ce00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100 # Each the real and generated data will be split into batches of this size (Since we only train on generated here)\n",
    "dropout_rate_choices = {0, 0.2, 0.5}\n",
    "gamma_focal_loss_choices = {2, 5} # Choices for the gamma parameter in the focal loss\n",
    "learning_rate = 0.001\n",
    "n_validation = 30 # Number of iterations between each validation run\n",
    "n_validation_minibatches = 3 # Number of minibatches to use for validation every n_validation iterations\n",
    "num_epochs = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e60fc99",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "868ef8b6",
   "metadata": {},
   "source": [
    "We can start by loading a pre-trained VGG16 model without the classification layers towards the end (Only the feature extractor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a976a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8433f526",
   "metadata": {},
   "source": [
    "We can now visualize its layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9614fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "018e9568",
   "metadata": {},
   "source": [
    "Because we are looking for a pre-trained feature extractor here, we decide to only use the features part and freeze its weights. We can then add a few subsequent layers to fine tune predictions. We can thus define the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a051bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=13, dropout_rate=0.5):\n",
    "        \n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        # Define the layers of the model\n",
    "        self.features = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1').features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4608, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Set the features to not require gradients\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7348424",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3c49179",
   "metadata": {},
   "source": [
    "We can start by finding the device to use for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1237640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.has_mps:\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61cb4352",
   "metadata": {},
   "source": [
    "We can then go ahead and define the loss function we will be using. Because we will opt for a balanced focal loss instead of a regular cross entropy loss which gives more importance to the classes that are harder to classify. We thus implement the focal loss defined by the following formula:\n",
    "$$\n",
    "FL(p_t) = -(1-p_t^{\\gamma})log(p_t)\n",
    "$$\n",
    "\n",
    "where gamma $\\gamma$ is a tunable hyperparameter. We can also further add an alpha term to handle class imbalance, making our loss function a class-balanced focal loss, as shown in https://github.com/AdeelH/pytorch-multi-class-focal-loss. \n",
    "Note: Since we have balanced classes thanks to oversmapling, we will not use the alpha parameter.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "057bb473",
   "metadata": {},
   "source": [
    "Finally, we need an accuracy metric to tune the hyperparameters of the model. We will opt for a balanced accuracy score, which is just regular classification accuracy but adapted to weigh each class by its frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66bd0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the accuracy metrics\n",
    "f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=13, average=\"weighted\").to(DEVICE)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=13, average=\"weighted\").to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ad6b2b4",
   "metadata": {},
   "source": [
    "We can now load a single example from the loader and display its label as well as its class proportion, which should be around 1/13 which is +- 8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f2ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_train_loader = get_loader(set_type=\"Generated\", set_name=\"train\", batch_size=128, balance=True)\n",
    "\n",
    "for i, (images, labels) in enumerate(gen_train_loader):\n",
    "    class_proportions = [(labels == i).sum() / len(labels) for i in range(13)]\n",
    "    plt.title(\"label: \" + str(labels[0].item()) + \" proportion: \" + str(class_proportions[labels[0].item()].item() * 100) + \"%\")\n",
    "    plt.imshow(images[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed6cd714",
   "metadata": {},
   "source": [
    "We can also define the following functions for saving the metrics collected during training (Depeding of which training strategy is being used: Training on generated data or on the real life data). We will plot these metrics later in the Results.ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7010d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_json_train_gen(gen_training_losses, gen_training_accs, gen_training_f1s, \\\n",
    "                         gen_validation_losses, gen_validation_accs, gen_validation_f1s, \\\n",
    "                            real_validation_losses, real_validation_accs, real_validation_f1s, \\\n",
    "                                real_validation_accs_full, gamma, batch_size, dropout_rate, learning_rate, \\\n",
    "                                    n_validation, n_validation_minibatches, num_epochs, best_real_acc, best_epoch):\n",
    "        \n",
    "    json_data = {\n",
    "        \"metrics\": {\n",
    "            \"gen_training_losses/iteration\": gen_training_losses,\n",
    "            \"gen_training_accs/iteration\": gen_training_accs,\n",
    "            \"gen_training_f1s/iteration\": gen_training_f1s,\n",
    "            \"gen_validation_losses/n_validation\": gen_validation_losses,\n",
    "            \"gen_validation_accs/n_validation\": gen_validation_accs,\n",
    "            \"gen_validation_f1s/n_validation\": gen_validation_f1s,\n",
    "            \"real_validation_losses/n_validation\": real_validation_losses,\n",
    "            \"real_validation_accs/n_validation\": real_validation_accs,\n",
    "            \"real_validation_f1s/n_validation\": real_validation_f1s,\n",
    "            \"real_validation_accs_full/epoch\": real_validation_accs_full\n",
    "        },\n",
    "        \"hyperparameters\": {\n",
    "            \"gamma\": gamma,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"dropout_rate\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"n_validation\": n_validation,\n",
    "            \"n_validation_minibatches\": n_validation_minibatches,\n",
    "            \"num_epochs\": num_epochs\n",
    "        },\n",
    "        \"peak_performance\": {\n",
    "            \"best_real_acc\": best_real_acc,\n",
    "            \"best_epoch\": best_epoch\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(f\"TRAIN_GEN/HP tuning results/gamma_{str(gamma)}_dropout_{str(dropout_rate)}.json\", \"w\") as json_file:\n",
    "        json.dump(json_data, json_file)\n",
    "\n",
    "\n",
    "def save_metrics_to_json_train_real(real_training_losses, real_training_accs, real_training_f1s, \\\n",
    "                                   real_validation_losses, real_validation_accs, real_validation_f1s, \\\n",
    "                                   real_validation_accs_full, gamma, batch_size, dropout_rate, learning_rate, \\\n",
    "                                   n_validation, n_validation_minibatches, num_epochs, best_real_acc, best_epoch, \\\n",
    "                                   full_dataset_used):\n",
    "\n",
    "    json_data = {\n",
    "        \"metrics\": {\n",
    "            \"real_training_losses/iteration\": real_training_losses,\n",
    "            \"real_training_accs/iteration\": real_training_accs,\n",
    "            \"real_training_f1s/iteration\": real_training_f1s,\n",
    "            \"real_validation_losses/n_validation\": real_validation_losses,\n",
    "            \"real_validation_accs/n_validation\": real_validation_accs,\n",
    "            \"real_validation_f1s/n_validation\": real_validation_f1s,\n",
    "            \"real_validation_accs_full/epoch\": real_validation_accs_full\n",
    "        },\n",
    "        \"hyperparameters\": {\n",
    "            \"gamma\": gamma,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"dropout_rate\": dropout_rate,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"n_validation\": n_validation,\n",
    "            \"n_validation_minibatches\": n_validation_minibatches,\n",
    "            \"num_epochs\": num_epochs\n",
    "        },\n",
    "        \"peak_performance\": {\n",
    "            \"best_real_acc\": best_real_acc,\n",
    "            \"best_epoch\": best_epoch\n",
    "        }\n",
    "    }\n",
    "\n",
    "    folder = \"TRAIN_FULL_REAL\" if full_dataset_used else \"TRAIN_VAL_REAL\"\n",
    "    with open(f\"./{folder}/HP tuning results/gamma_{str(gamma)}_dropout_{str(dropout_rate)}.json\", \"w\") as json_file:\n",
    "        json.dump(json_data, json_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce0e9ca4",
   "metadata": {},
   "source": [
    "We can now define an evaluate function that computes the average accuracy on the full real life validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644b8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(basemodel, real_val_loader):\n",
    "\n",
    "    # Set the model to eval mode\n",
    "    basemodel.eval()\n",
    "\n",
    "    # To compute the average validation accuracy\n",
    "    acc_val_sum = 0\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate through the full validation set\n",
    "        for X_val_real, y_val_real in real_val_loader:\n",
    "\n",
    "            # Move the data to the device\n",
    "            X_val_real = X_val_real.to(DEVICE)\n",
    "            y_val_real = y_val_real.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            y_val_pred_prob_real = basemodel(X_val_real)\n",
    "            y_val_pred_real = torch.argmax(y_val_pred_prob_real, dim=1)\n",
    "\n",
    "            # Compute the metrics\n",
    "            acc_val_sum += accuracy(y_val_pred_real, y_val_real).item()\n",
    "\n",
    "    # Compute the average accuracy\n",
    "    average_real_acc = acc_val_sum / len(real_val_loader)\n",
    "\n",
    "    return average_real_acc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9277b252",
   "metadata": {},
   "source": [
    "We also define a function to check if a model was already trained and load its checkpoint if it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67b8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_already_trained_gen(gamma, dropout_rate):\n",
    "    if os.path.exists(f\"./TRAIN_GEN/HP tuning results/gamma_{str(gamma)}_dropout_{str(dropout_rate)}.json\"):\n",
    "        \n",
    "        # Load the json file\n",
    "        with open(f\"./TRAIN_GEN/HP tuning results/gamma_{str(gamma)}_dropout_{str(dropout_rate)}.json\", \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        \n",
    "        # Check which epoch had the best real accuracy\n",
    "        best_epoch = json_data[\"peak_performance\"][\"best_epoch\"]\n",
    "\n",
    "        # Get the corresponding real accuracy\n",
    "        best_acc = json_data[\"peak_performance\"][\"best_real_acc\"]\n",
    "\n",
    "        # Find the model checkpoint corresponding to the best epoch\n",
    "        best_BASE_state_dict = torch.load(f\"./TRAIN_GEN/checkpoints/basemodel_gamma_{gamma}_dropout_{dropout_rate}_epoch_{best_epoch}.ckpt\")\n",
    "\n",
    "        return best_BASE_state_dict, best_acc\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d81644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_already_trained_real(gamma, dropout_rate, full_dataset_used=False):\n",
    "    # Folder to load metrics from\n",
    "    folder = \"TRAIN_FULL_REAL\" if full_dataset_used else \"TRAIN_VAL_REAL\"\n",
    "\n",
    "    if os.path.exists(f\"./{folder}/HP tuning results/gamma_{str(gamma)}_dropout_{str(dropout_rate)}.json\"):\n",
    "        \n",
    "        # Load the json file\n",
    "        with open(f\"./{folder}/HP tuning results/gamma_{str(gamma)}_dropout_{str(dropout_rate)}.json\", \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        \n",
    "        # Check which epoch had the best real accuracy\n",
    "        best_epoch = json_data[\"peak_performance\"][\"best_epoch\"]\n",
    "\n",
    "        # Get the corresponding real accuracy\n",
    "        best_acc = json_data[\"peak_performance\"][\"best_real_acc\"]\n",
    "\n",
    "        # Find the model checkpoint corresponding to the best epoch\n",
    "        best_BASE_state_dict = torch.load(f\"./{folder}/checkpoints/basemodel_gamma_{gamma}_dropout_{dropout_rate}_epoch_{best_epoch}.ckpt\")\n",
    "\n",
    "        return best_BASE_state_dict, best_acc\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6672cd8",
   "metadata": {},
   "source": [
    "We can now define a training function we will call for each hyperparameter combination. We again need one training function to train on the real life data and an equivalent to train on the generated data. To differentiate between training on the full and on a subset of the validation portion of the real life data in the real life training function, we will add a parameter called `full_dataset_used` to the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2001a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(gamma, dropout_rate, batch_size, hyperparameter_combination_number, \n",
    "                        learning_rate=learning_rate, n_validation=n_validation, \\\n",
    "                        n_validation_minibatches=n_validation_minibatches, num_epochs=num_epochs):\n",
    "    # Check whether the model has already been trained\n",
    "    best_BASE_state_dict, best_acc = check_already_trained_gen(gamma, dropout_rate)\n",
    "\n",
    "    # If the model has already been trained, return the best model and its accuracy\n",
    "    if best_BASE_state_dict is not None:\n",
    "        return best_BASE_state_dict, best_acc\n",
    "    \n",
    "    # Define the data loaders accounting for the batch size\n",
    "    train_loader = get_loader(set_type=\"Generated\", set_name=\"train\", batch_size=batch_size, balance=True)\n",
    "    gen_val_loader = get_loader(set_type=\"Generated\", set_name=\"validation\", batch_size=batch_size, balance=True)\n",
    "    real_val_loader = get_loader(set_type=\"Real\", set_name=\"validation\", batch_size=batch_size, balance=True)\n",
    "\n",
    "    # Define the new loss function (Taking into account gamma)\n",
    "    focal_loss = torch.hub.load(\n",
    "        'adeelh/pytorch-multi-class-focal-loss',\n",
    "        model='FocalLoss',\n",
    "        gamma=gamma, # No use of alpha since we have balanced classes now with the oversampling\n",
    "        reduction='mean',\n",
    "        force_reload=False,\n",
    "        verbose = False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    basemodel = BaseModel(dropout_rate=dropout_rate).to(DEVICE)      \n",
    "    opt = optim.Adam(basemodel.parameters(), lr=learning_rate)\n",
    "\n",
    "    # To store the metrics every iteration on 1 minibatch\n",
    "    gen_training_losses = []\n",
    "    gen_training_accs = []\n",
    "    gen_training_f1s = []\n",
    "\n",
    "    # To store the metrics every n_validation iterations on n_validation_minibatches\n",
    "    gen_validation_losses = []\n",
    "    gen_validation_accs = []\n",
    "    gen_validation_f1s = []\n",
    "    real_validation_losses = []\n",
    "    real_validation_accs = []\n",
    "    real_validation_f1s = []\n",
    "\n",
    "    # To store the accuracy of the epoch on the full real validation set\n",
    "    real_validation_accs_full = []\n",
    "\n",
    "    # To keep track of the best model (Best epoch)\n",
    "    best_real_acc = -1\n",
    "    best_model_state_dict = None\n",
    "    best_epoch = -1\n",
    "\n",
    "    # Compute the average accuracy on the validation set at epoch 0\n",
    "    average_acc = evaluate_epoch(basemodel, real_val_loader)\n",
    "    real_validation_accs_full.append(average_acc)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train the model\n",
    "        for iteration, (X_train_gen, y_train_gen) in tqdm(enumerate(train_loader)):\n",
    "            \n",
    "            # Set the model to training mode\n",
    "            basemodel.train()\n",
    "\n",
    "            # Move the data to the device\n",
    "            X_train_gen = X_train_gen.to(DEVICE)\n",
    "            y_train_gen = y_train_gen.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            y_train_pred_raw_gen = basemodel(X_train_gen)\n",
    "            y_train_pred_gen = torch.argmax(y_train_pred_raw_gen, dim=1)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_train = focal_loss(y_train_pred_raw_gen, y_train_gen.long())\n",
    "\n",
    "            # Compute the accuracy\n",
    "            acc_train = accuracy(y_train_pred_gen, y_train_gen)\n",
    "            f1_train = f1_score(y_train_pred_gen, y_train_gen)\n",
    "\n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss_train.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # Store the loss & accuracy\n",
    "            gen_training_losses.append(loss_train.item())\n",
    "            gen_training_accs.append(acc_train.item())\n",
    "            gen_training_f1s.append(f1_train.item())\n",
    "            \n",
    "            # Check if the model should be validated\n",
    "            if iteration == 0 or (iteration + 1) % n_validation == 0:\n",
    "                \n",
    "                # Set the model to evaluation mode\n",
    "                basemodel.eval()\n",
    "                \n",
    "                # Disable gradient calculation\n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    # 1) Evaluate on the generated validation set\n",
    "                    acc_val_sum = 0\n",
    "                    weighted_f1_val_sum = 0\n",
    "                    loss_val_sum = 0\n",
    "\n",
    "                    # Extract an iterator from the generated data loader\n",
    "                    gen_val_iter = iter(gen_val_loader)\n",
    "\n",
    "                    # Iterate for n_validation_minibatches\n",
    "                    for _ in range(n_validation_minibatches):\n",
    "\n",
    "                        # Get the next minibatch\n",
    "                        minibatch = next(gen_val_iter, None)\n",
    "                        if minibatch is None:\n",
    "                            gen_val_iter = iter(gen_val_loader)\n",
    "                            minibatch = next(gen_val_iter, None)\n",
    "                            \n",
    "                        # Extract the data\n",
    "                        X_val_gen, y_val_gen = minibatch\n",
    "\n",
    "                        # Move the data to the device\n",
    "                        X_val_gen = X_val_gen.to(DEVICE)\n",
    "                        y_val_gen = y_val_gen.to(DEVICE)\n",
    "\n",
    "                        # Forward pass\n",
    "                        y_val_pred_raw_gen = basemodel(X_val_gen)\n",
    "                        y_val_pred_gen = torch.argmax(y_val_pred_raw_gen, dim=1)\n",
    "\n",
    "                        # Compute the metrics\n",
    "                        acc_val_sum += accuracy(y_val_pred_gen, y_val_gen)\n",
    "                        weighted_f1_val_sum += f1_score(y_val_pred_gen, y_val_gen)\n",
    "                        loss_val_sum += focal_loss(y_val_pred_raw_gen, y_val_gen)\n",
    "\n",
    "                    # Compute the average metrics\n",
    "                    acc_val_gen = acc_val_sum / n_validation_minibatches\n",
    "                    loss_val_gen = loss_val_sum / n_validation_minibatches\n",
    "                    weighted_f1_val_gen = weighted_f1_val_sum / n_validation_minibatches\n",
    "\n",
    "\n",
    "                    # 2) Repeat on the real validation set\n",
    "\n",
    "                    acc_val_sum = 0\n",
    "                    weighted_f1_val_sum = 0\n",
    "                    loss_val_sum = 0\n",
    "\n",
    "                    # Extract an iterator from the generated data loader\n",
    "                    real_val_iter = iter(real_val_loader)\n",
    "\n",
    "                    # Iterate for n_validation_minibatches\n",
    "                    for _ in range(n_validation_minibatches):\n",
    "\n",
    "                        # Get the next minibatch\n",
    "                        minibatch = next(real_val_iter, None)\n",
    "                        if minibatch is None:\n",
    "                            real_val_iter = iter(real_val_loader)\n",
    "                            minibatch = next(real_val_iter, None)\n",
    "\n",
    "                        # Extract the data\n",
    "                        X_val_real, y_val_real = minibatch\n",
    "                            \n",
    "                        # Move the data to the device\n",
    "                        X_val_real = X_val_real.to(DEVICE)\n",
    "                        y_val_real = y_val_real.to(DEVICE)\n",
    "\n",
    "                        # Forward pass\n",
    "                        y_val_pred_raw_real = basemodel(X_val_real)\n",
    "                        y_val_pred_real = torch.argmax(y_val_pred_raw_real, dim=1)\n",
    "\n",
    "                        # Compute the metrics\n",
    "                        acc_val_sum += accuracy(y_val_pred_real, y_val_real)\n",
    "                        weighted_f1_val_sum += f1_score(y_val_pred_real, y_val_real)\n",
    "                        loss_val_sum += focal_loss(y_val_pred_raw_real, y_val_real)\n",
    "\n",
    "                    # Compute the average metrics\n",
    "                    acc_val_real = acc_val_sum / n_validation_minibatches\n",
    "                    loss_val_real = loss_val_sum / n_validation_minibatches\n",
    "                    weighted_f1_val_real = weighted_f1_val_sum / n_validation_minibatches\n",
    "\n",
    "                    # Store all 6 metrics\n",
    "                    gen_validation_losses.append(loss_val_gen.item())\n",
    "                    gen_validation_accs.append(acc_val_gen.item())\n",
    "                    gen_validation_f1s.append(weighted_f1_val_gen.item())\n",
    "                    real_validation_losses.append(loss_val_real.item())\n",
    "                    real_validation_accs.append(acc_val_real.item())\n",
    "                    real_validation_f1s.append(weighted_f1_val_real.item())\n",
    "\n",
    "                    # Print an update -- Only show the last print statement\n",
    "                    clear_output(wait=True)\n",
    "                    print('----------------------------------------------------------------')\n",
    "                    print(f'TRAINING HP COMBINATION  [#{hyperparameter_combination_number}] -- EPOCH [{epoch+1}] --  ITERATION [{iteration+1}]')\n",
    "                    print(f'CURRENT BEST EPOCH: {best_epoch} -- CURRENT BEST FULL VALIDATION SET ACCURACY: {best_real_acc}')\n",
    "                    print('----------------------------------------------------------------')\n",
    "                    print(f'TRAINING => Loss: {loss_train} -- Acc: {acc_train} -- F1: {f1_train}')\n",
    "                    print(f'GENERATED VALIDATION => Loss: {loss_val_gen} -- Acc: {acc_val_gen} -- F1: {weighted_f1_val_gen}')\n",
    "                    print(f'REAL VALIDATION => Loss: {loss_val_real} -- Acc: {acc_val_real} -- F1: {weighted_f1_val_real}')\n",
    "                    print('----------------------------------------------------------------')\n",
    "                    \n",
    "        # Save the model every epoch as a checkpoint \n",
    "        torch.save(basemodel.state_dict(), f'./TRAIN_GEN/checkpoints/basemodel_gamma_{gamma}_dropout_{dropout_rate}_epoch_{epoch+1}.ckpt')\n",
    "\n",
    "        # Check whether to overwrite the best model by computing the validation accuracy on the full real life validation set\n",
    "        average_real_acc = evaluate_epoch(basemodel, real_val_loader)\n",
    "\n",
    "        # Append the average real validation accuracy of the epoch to the corresponding array\n",
    "        real_validation_accs_full.append(average_real_acc)\n",
    "\n",
    "        # Check whether the current version of the model is the best one\n",
    "        if best_model_state_dict is None or average_real_acc > best_real_acc:\n",
    "            best_real_acc = average_real_acc\n",
    "            best_model_state_dict = basemodel.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "        \n",
    "    # Plot and save the metrics\n",
    "    save_metrics_to_json_train_gen(gen_training_losses, gen_training_accs, gen_training_f1s, gen_validation_losses, \\\n",
    "                                gen_validation_accs, gen_validation_f1s, real_validation_losses, real_validation_accs, \\\n",
    "                                real_validation_f1s, real_validation_accs_full, gamma, batch_size, dropout_rate, learning_rate, \\\n",
    "                                n_validation, n_validation_minibatches, num_epochs, best_real_acc, best_epoch)\n",
    "    \n",
    "    return best_model_state_dict, best_real_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e886d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_real(full_dataset_used, gamma, dropout_rate, batch_size, hyperparameter_combination_number,\n",
    "              learning_rate=learning_rate, n_validation=n_validation,\n",
    "              n_validation_minibatches=n_validation_minibatches, num_epochs=num_epochs):\n",
    "    \n",
    "    # Check whether the model has already been trained\n",
    "    best_BASE_state_dict, best_acc = check_already_trained_real(gamma, dropout_rate, full_dataset_used)\n",
    "\n",
    "    # If the model has already been trained, return the best model and its accuracy\n",
    "    if best_BASE_state_dict is not None:\n",
    "        return best_BASE_state_dict, best_acc\n",
    "\n",
    "    # Define the data loaders accounting for the batch size\n",
    "    if full_dataset_used:\n",
    "        train_loader = get_loader(set_type=\"Real\", set_name=\"train\", batch_size=batch_size, balance=True)\n",
    "        val_loader = get_loader(set_type=\"Real\", set_name=\"validation\", batch_size=batch_size, balance=True)\n",
    "    else:\n",
    "        # Extract a version of the real data where the training set is just 80% of the full validation set\n",
    "        # The validation set becomes 20% of the initial validation set\n",
    "        full_val_real_dataset_length = len(get_loader(type=\"Real\", set_name=\"validation\", batch_size=batch_size, balance=True).images)\n",
    "        train_loader = get_loader(\n",
    "            set_type=\"Real\", set_name=\"validation\", batch_size=batch_size, balance=True, filter_array=np.arange(0, int(0.8*full_val_real_dataset_length)))\n",
    "        val_loader = get_loader(\n",
    "            set_type=\"Real\", set_name=\"validation\", batch_size=batch_size, balance=True, filter_array=np.arange(int(0.8*full_val_real_dataset_length), full_val_real_dataset_length))\n",
    "\n",
    "    # Define the new loss function (Taking into account gamma)\n",
    "    focal_loss = torch.hub.load(\n",
    "        'adeelh/pytorch-multi-class-focal-loss',\n",
    "        model='FocalLoss',\n",
    "        gamma=gamma,  # No use of alpha since we have balanced classes now with the oversampling\n",
    "        reduction='mean',\n",
    "        force_reload=False,\n",
    "        verbose=False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    basemodel = BaseModel(dropout_rate=dropout_rate).to(DEVICE)\n",
    "    opt = optim.Adam(basemodel.parameters(), lr=learning_rate)\n",
    "\n",
    "    # To store the metrics every iteration on 1 minibatch\n",
    "    training_losses = []\n",
    "    training_accs = []\n",
    "    training_f1s = []\n",
    "\n",
    "    # To store the metrics every n_validation iterations on n_validation_minibatches\n",
    "    validation_losses = []\n",
    "    validation_accs = []\n",
    "    validation_f1s = []\n",
    "\n",
    "    # To store the accuracy of the epoch on the full real validation set\n",
    "    validation_accs_full = []\n",
    "\n",
    "    # Folder to save metrics to\n",
    "    folder = \"TRAIN_FULL_REAL\" if full_dataset_used else \"TRAIN_VAL_REAL\"\n",
    "\n",
    "    # To keep track of the best model (Best epoch)\n",
    "    best_acc = -1\n",
    "    best_model_state_dict = None\n",
    "    best_epoch = -1\n",
    "\n",
    "    # Compute the average accuracy on the validation set at epoch 0\n",
    "    average_acc = evaluate_epoch(basemodel, val_loader)\n",
    "    validation_accs_full.append(average_acc)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train the model\n",
    "        for iteration, (X_train, y_train) in tqdm(enumerate(train_loader)):\n",
    "\n",
    "            # Set the model to training mode\n",
    "            basemodel.train()\n",
    "\n",
    "            # Move the data to the device\n",
    "            X_train = X_train.to(DEVICE)\n",
    "            y_train = y_train.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            y_train_pred_raw = basemodel(X_train)\n",
    "            y_train_pred = torch.argmax(y_train_pred_raw, dim=1)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss_train = focal_loss(y_train_pred_raw, y_train.long())\n",
    "\n",
    "            # Compute the accuracy\n",
    "            acc_train = accuracy(y_train_pred, y_train)\n",
    "            f1_train = f1_score(y_train_pred, y_train)\n",
    "\n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss_train.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # Store the loss & accuracy\n",
    "            training_losses.append(loss_train.item())\n",
    "            training_accs.append(acc_train.item())\n",
    "            training_f1s.append(f1_train.item())\n",
    "\n",
    "            # Check if the model should be validated\n",
    "            if iteration == 0 or (iteration + 1) % n_validation == 0:\n",
    "\n",
    "                # Set the model to evaluation mode\n",
    "                basemodel.eval()\n",
    "\n",
    "                # Disable gradient calculation\n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    # Compute all metrics on the real life validation dataset\n",
    "                    acc_val_sum = 0\n",
    "                    weighted_f1_val_sum = 0\n",
    "                    loss_val_sum = 0\n",
    "\n",
    "                    # Extract an iterator from the generated data loader\n",
    "                    val_iter = iter(val_loader)\n",
    "\n",
    "                    # Iterate for n_validation_minibatches\n",
    "                    for _ in range(n_validation_minibatches):\n",
    "\n",
    "                        # Get the next minibatch\n",
    "                        minibatch = next(val_iter, None)\n",
    "                        if minibatch is None:\n",
    "                            val_iter = iter(val_loader)\n",
    "                            minibatch = next(val_iter, None)\n",
    "\n",
    "                        # Extract the data\n",
    "                        X_val, y_val = minibatch\n",
    "\n",
    "                        # Move the data to the device\n",
    "                        X_val = X_val.to(DEVICE)\n",
    "                        y_val = y_val.to(DEVICE)\n",
    "\n",
    "                        # Forward pass\n",
    "                        y_val_pred_raw = basemodel(X_val)\n",
    "                        y_val_pred = torch.argmax(y_val_pred_raw, dim=1)\n",
    "\n",
    "                        # Compute the metrics\n",
    "                        acc_val_sum += accuracy(y_val_pred, y_val)\n",
    "                        weighted_f1_val_sum += f1_score(y_val_pred, y_val)\n",
    "                        loss_val_sum += focal_loss(y_val_pred_raw, y_val)\n",
    "\n",
    "                    # Compute the average metrics\n",
    "                    acc_val = acc_val_sum / n_validation_minibatches\n",
    "                    loss_val = loss_val_sum / n_validation_minibatches\n",
    "                    weighted_f1_val = weighted_f1_val_sum / n_validation_minibatches\n",
    "\n",
    "                    # Store all 6 metrics\n",
    "                    validation_losses.append(loss_val.item())\n",
    "                    validation_accs.append(acc_val.item())\n",
    "                    validation_f1s.append(weighted_f1_val.item())\n",
    "\n",
    "                    # Print an update -- Only show the last print statement\n",
    "                    clear_output(wait=True)\n",
    "                    print('----------------------------------------------------------------')\n",
    "                    print(f'TRAINING HP COMBINATION  [#{hyperparameter_combination_number}] -- EPOCH [{epoch+1}] --  ITERATION [{iteration+1}]')\n",
    "                    print(f'CURRENT BEST EPOCH: {best_epoch} -- CURRENT BEST FULL VALIDATION SET ACCURACY: {best_acc}')\n",
    "                    print('----------------------------------------------------------------')\n",
    "                    print(f'TRAINING => Loss: {loss_train} -- Acc: {acc_train} -- F1: {f1_train}')\n",
    "                    print(f'VALIDATION => Loss: {loss_val} -- Acc: {acc_val} -- F1: {weighted_f1_val}')\n",
    "                    print('----------------------------------------------------------------')\n",
    "\n",
    "        # Save the model every epoch as a checkpoint\n",
    "        torch.save(basemodel.state_dict(), f'./{folder}/checkpoints/basemodel_gamma_{gamma}_dropout_{dropout_rate}_epoch_{epoch+1}.ckpt')\n",
    "\n",
    "        # Check whether to overwrite the best model by computing the validation accuracy on the full real life validation set\n",
    "\n",
    "        # Compute the average acc on the full real validation set\n",
    "        average_acc = evaluate_epoch(basemodel, val_loader)\n",
    "\n",
    "        # Append the average real validation accuracy of the epoch to the corresponding array\n",
    "        validation_accs_full.append(average_acc)\n",
    "\n",
    "        # Check whether the current version of the model is the best one\n",
    "        if best_model_state_dict is None or average_acc > best_acc:\n",
    "            best_acc = average_acc\n",
    "            best_model_state_dict = basemodel.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # Plot and save the metrics\n",
    "    save_metrics_to_json_train_real(training_losses, training_accs, training_f1s, validation_losses,\n",
    "                                   validation_accs, validation_f1s, validation_accs_full, gamma, batch_size, dropout_rate, learning_rate,\n",
    "                                   n_validation, n_validation_minibatches, num_epochs, best_acc, best_epoch, full_dataset_used)\n",
    "\n",
    "    return best_model_state_dict, best_acc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e0fb873",
   "metadata": {},
   "source": [
    "We can now proceed to train our model on the generated dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3473931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r30it [00:35,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "TRAINING HP COMBINATION  [#1] -- EPOCH [1] --  ITERATION [30]\n",
      "CURRENT BEST EPOCH: -1 -- CURRENT BEST FULL VALIDATION SET ACCURACY: -1\n",
      "----------------------------------------------------------------\n",
      "TRAINING => Loss: 0.16766060888767242 -- Acc: 0.8600000143051147 -- F1: 0.8547358512878418\n",
      "GENERATED VALIDATION => Loss: 0.1362764686346054 -- Acc: 0.8920000195503235 -- F1: 0.8902121782302856\n",
      "REAL VALIDATION => Loss: 1.5796113014221191 -- Acc: 0.39000001549720764 -- F1: 0.37623026967048645\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:43,  1.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\Models\\BASE\\Simple model.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m gamma \u001b[39min\u001b[39;00m gamma_focal_loss_choices:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mfor\u001b[39;00m dropout_rate \u001b[39min\u001b[39;00m dropout_rate_choices:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         cur_best_model_state_dict, cur_best_real_acc \u001b[39m=\u001b[39m train_gen(gamma, dropout_rate, batch_size, model_count)  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39m# Create a row to add to the dataframe\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         row \u001b[39m=\u001b[39m [gamma, dropout_rate, cur_best_real_acc]\n",
      "\u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\Models\\BASE\\Simple model.ipynb Cell 34\u001b[0m in \u001b[0;36mtrain_gen\u001b[1;34m(gamma, dropout_rate, batch_size, hyperparameter_combination_number, learning_rate, n_validation, n_validation_minibatches, num_epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m real_validation_accs_full\u001b[39m.\u001b[39mappend(average_acc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mfor\u001b[39;00m iteration, (X_train_gen, y_train_gen) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(train_loader)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         basemodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/BASE/Simple%20model.ipynb#X45sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m         \u001b[39m# Move the data to the device\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\Models\\BASE\\../../Datasets\\Custom_Dataset.py:84\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     82\u001b[0m     img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages[idx])\n\u001b[1;32m---> 84\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img_path)\n\u001b[0;32m     85\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n\u001b[0;32m     87\u001b[0m     \u001b[39m# Convert the label to int instead of float\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\PIL\\Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2950\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   2952\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 2953\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   2954\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2956\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# To store the best model\n",
    "best_real_acc = -1\n",
    "\n",
    "# Store the validation accuracies\n",
    "hp_final_accs = pd.DataFrame(columns=[\"Gamma\", \"Dropout Rate\", \"Best Validation Accuracy\"])\n",
    "\n",
    "# To keep track of the number of models trained\n",
    "model_count = 1\n",
    "\n",
    "for gamma in gamma_focal_loss_choices:\n",
    "\n",
    "    for dropout_rate in dropout_rate_choices:\n",
    "        \n",
    "        # Train the model\n",
    "        cur_best_model_state_dict, cur_best_real_acc = train_gen(gamma, dropout_rate, batch_size, model_count)  \n",
    "\n",
    "        # Create a row to add to the dataframe\n",
    "        row = [gamma, dropout_rate, cur_best_real_acc]\n",
    "        \n",
    "        # Store it\n",
    "        hp_final_accs.loc[len(hp_final_accs)] = row\n",
    "\n",
    "        # Compare to the best model\n",
    "        if cur_best_real_acc > best_real_acc:\n",
    "            best_real_acc = cur_best_real_acc\n",
    "            torch.save(cur_best_model_state_dict, f'./TRAIN_GEN/best_BASE_TRAIN_GEN_model.ckpt')\n",
    "\n",
    "        # Save (overwrite) the dataframe as a table every time a model finish training so that we can keep track of the progress\n",
    "        hp_final_accs.to_csv('./TRAIN_GEN/HP_best_real_accuracy_comparison_table.csv', index=False)\n",
    "\n",
    "        # Increment the model count\n",
    "        model_count += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9145aade",
   "metadata": {},
   "source": [
    "Next, we train based on an 80% split of the validation subset of the real-life data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2925738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1it [00:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "TRAINING HP COMBINATION  [#6] -- EPOCH [5] --  ITERATION [1]\n",
      "CURRENT BEST EPOCH: 4 -- CURRENT BEST FULL VALIDATION SET ACCURACY: 0.9499999965940203\n",
      "----------------------------------------------------------------\n",
      "TRAINING => Loss: 0.045444998890161514 -- Acc: 0.9699999094009399 -- F1: 0.970859944820404\n",
      "VALIDATION => Loss: 0.18353727459907532 -- Acc: 0.9199999570846558 -- F1: 0.9185091257095337\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:06,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# To store the best model\n",
    "best_real_acc = -1\n",
    "\n",
    "# Store the validation accuracies\n",
    "hp_final_accs = pd.DataFrame(columns=[\"Gamma\", \"Dropout Rate\", \"Best Validation Accuracy\"])\n",
    "\n",
    "# To keep track of the number of models trained\n",
    "model_count = 1\n",
    "\n",
    "for gamma in gamma_focal_loss_choices:\n",
    "\n",
    "    for dropout_rate in dropout_rate_choices:\n",
    "\n",
    "        # Train the model\n",
    "        cur_best_model_state_dict, cur_best_real_acc = train_real(False, gamma, dropout_rate, batch_size, model_count)\n",
    "\n",
    "        # Create a row to add to the dataframe\n",
    "        row = [gamma, dropout_rate, cur_best_real_acc]\n",
    "\n",
    "        # Store it\n",
    "        hp_final_accs.loc[len(hp_final_accs)] = row\n",
    "\n",
    "        # Compare to the best model\n",
    "        if cur_best_real_acc > best_real_acc:\n",
    "            best_real_acc = cur_best_real_acc\n",
    "            torch.save(cur_best_model_state_dict,\n",
    "                        f'./TRAIN_VAL_REAL/best_BASE_TRAIN_VAL_REAL_model.ckpt')\n",
    "\n",
    "        # Save (overwrite) the dataframe as a table every time a model finish training so that we can keep track of the progress\n",
    "        hp_final_accs.to_csv(\n",
    "            './TRAIN_VAL_REAL/HP_best_real_accuracy_comparison_table.csv', index=False)\n",
    "        \n",
    "        # Increment the model count\n",
    "        model_count += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64e5fcf3",
   "metadata": {},
   "source": [
    "Finally, we use the full training real-life data as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867043f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r240it [01:01,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "TRAINING HP COMBINATION  [#6] -- EPOCH [5] --  ITERATION [240]\n",
      "CURRENT BEST EPOCH: 1 -- CURRENT BEST FULL VALIDATION SET ACCURACY: 0.9696875028312206\n",
      "----------------------------------------------------------------\n",
      "TRAINING => Loss: 0.002463064156472683 -- Acc: 1.0 -- F1: 1.0\n",
      "VALIDATION => Loss: 0.06763249635696411 -- Acc: 0.9779999852180481 -- F1: 0.9784014821052551\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [01:04,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# To store the best model\n",
    "best_real_acc = -1\n",
    "\n",
    "# Store the validation accuracies\n",
    "hp_final_accs = pd.DataFrame(\n",
    "    columns=[\"Gamma\", \"Dropout Rate\", \"Best Validation Accuracy\"])\n",
    "\n",
    "# To keep track of the number of models trained\n",
    "model_count = 1\n",
    "\n",
    "for gamma in gamma_focal_loss_choices:\n",
    "\n",
    "    for dropout_rate in dropout_rate_choices:\n",
    "\n",
    "        # Train the model\n",
    "        cur_best_model_state_dict, cur_best_real_acc = train_real(True, gamma, dropout_rate, batch_size, model_count)\n",
    "\n",
    "        # Create a row to add to the dataframe\n",
    "        row = [gamma, dropout_rate, cur_best_real_acc]\n",
    "\n",
    "        # Store it\n",
    "        hp_final_accs.loc[len(hp_final_accs)] = row\n",
    "\n",
    "        # Compare to the best model\n",
    "        if cur_best_real_acc > best_real_acc:\n",
    "            best_real_acc = cur_best_real_acc\n",
    "            torch.save(cur_best_model_state_dict,\n",
    "                        f'./TRAIN_FULL_REAL/best_BASE_TRAIN_FULL_REAL_model.ckpt')\n",
    "\n",
    "        # Save (overwrite) the dataframe as a table every time a model finish training so that we can keep track of the progress\n",
    "        hp_final_accs.to_csv(\n",
    "            './TRAIN_FULL_REAL/HP_best_real_accuracy_comparison_table.csv', index=False)\n",
    "        \n",
    "        # Increment the model count\n",
    "        model_count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
