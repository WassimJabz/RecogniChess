{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b950cda7",
   "metadata": {},
   "source": [
    "# Imports and overview\n",
    "\n",
    "This notebook implements the CORAL model from https://arxiv.org/pdf/1511.05547.pdf. It is inspired from https://github.com/SSARCandy/DeepCORAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144fa7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now load the dependencies\n",
    "%matplotlib inline \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../Datasets/\")\n",
    "from Custom_Dataset import *\n",
    "\n",
    "# Clear the cache of CUDA\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6211a13b",
   "metadata": {},
   "source": [
    "We can start by setting a seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356ddda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21d2610c270>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6fe08f8",
   "metadata": {},
   "source": [
    "For reference, here is the architecture of the model we will implement:\n",
    "\n",
    "<img src=\"CORAL_architecture.png\" align=\"center\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b93703ce",
   "metadata": {},
   "source": [
    "# Hyperparameter choices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b259e4e1",
   "metadata": {},
   "source": [
    "We create a cell to hold the hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ce00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_choices = {0.0005, 0.001}\n",
    "batch_size = 100 # Each the real and generated data will be split into batches of this size (Since we only train on generated here)\n",
    "num_epochs = 30 # Number of epochs to train for\n",
    "# Choices for the gamma parameter in the focal loss\n",
    "gamma_focal_loss_choices = {2, 5}\n",
    "n_validation = 30 # Number of iterations between each validation run\n",
    "n_validation_minibatches = 3 # Number of minibatches to use for validation\n",
    "lambda_max_DA_choices = {0.1, 1, 10}  # Weight of the coral loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e60fc99",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "868ef8b6",
   "metadata": {},
   "source": [
    "We can start by loading a pre-trained VGG16 model without the classification layers towards the end (Only the feature extractor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a976a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8433f526",
   "metadata": {},
   "source": [
    "We can now visualize its layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9614fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "018e9568",
   "metadata": {},
   "source": [
    "Because we are looking for a pre-trained feature extractor here, we decide to only use the features part and freeze its weights. We can then add a few subsequent layers to fine tune predictions. We can thus define the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a051bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoralModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=13):\n",
    "        \n",
    "        super(CoralModel, self).__init__()\n",
    "        \n",
    "        # Define the layers of the model\n",
    "        self.features = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1').features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4608, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Freeze all the weights in modules 0 up-to and including 25\n",
    "        for param in self.features[:25].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.features(x)\n",
    "        h = torch.flatten(h, 1)\n",
    "        output = self.classifier(h)\n",
    "        return h, output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7348424",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3c49179",
   "metadata": {},
   "source": [
    "We can start by finding the device to use for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1237640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.has_mps:\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61cb4352",
   "metadata": {},
   "source": [
    "We can then go ahead and define the loss function we will be using. \n",
    "\n",
    "According to the specified model architecture, the CORAL model utilizes two loss functions. The first one is the classification loss, for whihc we will opt for a balanced focal loss rather than the regular cross-entropy loss. The aim is to assign greater importance to the classes that are more challenging to classify. The focal loss can be defined using the following formula:\n",
    "\n",
    "$$\n",
    "FL(p_t) = -(1-p_t^{\\gamma})log(p_t)\n",
    "$$\n",
    "\n",
    "where gamma $\\gamma$ is a tunable hyperparameter. We can also further add an alpha term to handle class imbalance, making our loss function a class-balanced focal loss, as shown in https://github.com/AdeelH/pytorch-multi-class-focal-loss. \n",
    "Note: Since we have balanced classes thanks to oversmapling, we will not use the alpha parameter.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "304c6a68",
   "metadata": {},
   "source": [
    "The second loss is the Coral loss. Coral loss is a type of distance metric used to align two sets of feature representations. It stands for \"correlation alignment\".\n",
    "\n",
    "The Coral loss aims to minimize the domain shift between two distributions by aligning the second-order statistics of their features. It computes the covariance matrix of the source and target features and then minimizes the Frobenius norm between the difference of the two covariance matrices. This way, the correlation between the features is preserved and domain shift is reduced.\n",
    "\n",
    "The Coral loss can be formulated as:\n",
    "\n",
    "$$\n",
    "L_{coral}(X_s, X_t) = \\lVert C_s - C_t \\rVert_{F}^2\n",
    "$$\n",
    "\n",
    "where $X_s$ and $X_t$ are the source and target feature representations respectively, and $C_s$ and $C_t$ are the covariance matrices of the source and target features.\n",
    "\n",
    "In addition to the loss function, a helper function can be defined to compute the covariance matrix:\n",
    "\n",
    "$$\n",
    "C(X) = \\frac{1}{n-1}(X-\\bar{X})^T(X-\\bar{X})\n",
    "$$\n",
    "\n",
    "where $X$ is a matrix of feature representations and $\\bar{X}$ is the mean of each feature. The following code is taken from the mentionned github repository: https://github.com/SSARCandy/DeepCORAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734c90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CORAL_loss(source, target):\n",
    "\n",
    "\t# Number of features in the hidden representation\n",
    "\td = source.data.shape[1]\n",
    "\n",
    "    # source covariance\n",
    "\txm = torch.mean(source, 0, keepdim=True) - source\n",
    "\txc = xm.t() @ xm\n",
    "\n",
    "    # target covariance\n",
    "\txmt = torch.mean(target, 0, keepdim=True) - target\n",
    "\txct = xmt.t() @ xmt\n",
    "\n",
    "    # frobenius norm between source and target\n",
    "\tloss = torch.mean(torch.mul((xc - xct), (xc - xct)))\n",
    "\tloss = loss/(4*d*d)\n",
    "\n",
    "\treturn loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ecaecd",
   "metadata": {},
   "source": [
    "The total loss used in the backward step of our model is therefore represented by the following equation:\n",
    "\n",
    "$$\n",
    "TotalLoss = ClassificationLoss + \\lambda DomainLoss\n",
    "$$\n",
    "$$\n",
    "TotalLoss = FC + \\lambda L_{coral}(X_s, X_t)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e28a4adc",
   "metadata": {},
   "source": [
    "We also adjust the hyperparameter $\\lambda$, which determines the weight of the coral loss term in the total loss function.\" In other words, $\\lambda$ controls the contribution of the coral loss to the overall loss value, with larger values of $\\lambda$ giving the coral loss term more weight in the optimization process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "057bb473",
   "metadata": {},
   "source": [
    "Finally, we need an accuracy metric to tune the hyperparameters of the model. We will opt for a balanced accuracy score, which is just regular classification accuracy but adapted to weigh each class by its frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ba9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=13, average=\"weighted\").to(DEVICE)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=13, average=\"weighted\").to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75a78aec",
   "metadata": {},
   "source": [
    "We can also define the following function for saving the metrics collected during training. We will plot these metrics later in the Results.ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "162e9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_json(training_total_losses, training_coral_losses, gen_training_classification_losses, gen_training_accs, \\\n",
    "                           gen_training_f1s, gen_validation_accs, gen_validation_f1s, real_validation_accs, \\\n",
    "                              real_validation_f1s, validation_total_losses_using_gen_classification_losses, validation_CORAL_losses, \\\n",
    "                                gen_validation_classification_losses, real_validation_classification_losses, real_validation_accs_full, \\\n",
    "                         learning_rate, lambda_max_DA, gamma_focal_loss,  batch_size, n_validation, n_validation_minibatches, num_epochs, \\\n",
    "                          best_real_acc, best_epoch):\n",
    "\n",
    "    json_data = {\n",
    "        \"metrics\": {\n",
    "            \"training_total_losses/iteration\": training_total_losses,\n",
    "            \"training_coral_losses/iteration\": training_coral_losses,\n",
    "            \"gen_training_classification_losses/iteration\": gen_training_classification_losses,\n",
    "            \"gen_training_accs/iteration\": gen_training_accs,\n",
    "            \"gen_training_f1s/iteration\": gen_training_f1s,\n",
    "            \"gen_validation_accs/n_validation\": gen_validation_accs,\n",
    "            \"gen_validation_f1s/n_validation\": gen_validation_f1s,\n",
    "            \"real_validation_accs/n_validation\": real_validation_accs,\n",
    "            \"real_validation_f1s/n_validation\": real_validation_f1s,\n",
    "            \"validation_total_losses_using_gen_classification_losses/n_validation\": validation_total_losses_using_gen_classification_losses,\n",
    "            \"validation_CORAL_losses/n_validation\": validation_CORAL_losses,\n",
    "            \"gen_validation_classification_losses/n_validation\": gen_validation_classification_losses,\n",
    "            \"real_validation_classification_losses/n_validation\": real_validation_classification_losses,\n",
    "            \"real_validation_accs_full/epoch\": real_validation_accs_full\n",
    "        },\n",
    "        \"hyperparameters\": {\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"lambda_max_DA\": lambda_max_DA,\n",
    "            \"gamma_focal_loss\": gamma_focal_loss,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"n_validation\": n_validation,\n",
    "            \"n_validation_minibatches\": n_validation_minibatches,\n",
    "            \"num_epochs\": num_epochs\n",
    "        },\n",
    "        \"peak_performance\": {\n",
    "            \"best_real_acc\": best_real_acc,\n",
    "            \"best_epoch\": best_epoch\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    with open(f\"HP tuning results/lr_{str(learning_rate)}_lambdacoralmax_{str(lambda_max_DA)}_gamma_{gamma_focal_loss}.json\", \"w\") as json_file:\n",
    "        json.dump(json_data, json_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2aeabf",
   "metadata": {},
   "source": [
    "We start by defining a function that will evaluate the model on the full validation dataset every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73edab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(coralmodel, real_val_loader):\n",
    "\n",
    "    # Set the model to eval mode\n",
    "    coralmodel.eval()\n",
    "\n",
    "    # To compute the average validation accuracy\n",
    "    acc_val_sum = 0\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate through the full validation set\n",
    "        for X_val_real, y_val_real in real_val_loader:\n",
    "\n",
    "            # Move the data to the device\n",
    "            X_val_real = X_val_real.to(DEVICE)\n",
    "            y_val_real = y_val_real.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            _, y_val_pred_prob_real = coralmodel(X_val_real)\n",
    "            y_val_pred_real = torch.argmax(y_val_pred_prob_real, dim=1)\n",
    "\n",
    "            # Compute the metrics\n",
    "            acc_val_sum += accuracy(y_val_pred_real, y_val_real).item()\n",
    "\n",
    "    # Compute the average accuracy\n",
    "    average_real_acc = acc_val_sum / len(real_val_loader)\n",
    "\n",
    "    return average_real_acc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5c3262b",
   "metadata": {},
   "source": [
    "We also define a function to check if a model was already trained and load its checkpoint if it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f99598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_already_trained(lambda_DA, learning_rate, gamma_focal_loss):\n",
    "    if os.path.exists(f\"./HP tuning results/lr_{str(learning_rate)}_lambdacoralmax_{str(lambda_DA)}_gamma_{gamma_focal_loss}.json\"):\n",
    "        \n",
    "        # Load the json file\n",
    "        with open(f\"./HP tuning results/lr_{str(learning_rate)}_lambdacoralmax_{str(lambda_DA)}_gamma_{gamma_focal_loss}.json\", \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        \n",
    "        # Check which epoch had the best real accuracy\n",
    "        best_epoch = json_data[\"peak_performance\"][\"best_epoch\"]\n",
    "\n",
    "        # Get the corresponding real accuracy\n",
    "        best_acc = json_data[\"peak_performance\"][\"best_real_acc\"]\n",
    "\n",
    "        # Find the model checkpoint corresponding to the best epoch\n",
    "        best_CORAL_state_dict = torch.load(f\"./checkpoints/coralmodel_lr_{str(learning_rate)}_lambdamax_{str(lambda_DA)}_gamma_{gamma_focal_loss}_epoch_{best_epoch}.ckpt\")\n",
    "\n",
    "        return best_CORAL_state_dict, best_acc\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5432880d",
   "metadata": {},
   "source": [
    "We can now define a training function we will call for each hyperparameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635111f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hyperparameter_combination_number, learning_rate, lambda_max_DA, gamma_focal_loss, batch_size=batch_size, n_validation=n_validation, \\\n",
    "          n_validation_minibatches=n_validation_minibatches, num_epochs=num_epochs):\n",
    "\n",
    "    # Check whether the model has already been trained\n",
    "    best_CORAL_state_dict, best_acc = check_already_trained(lambda_max_DA, learning_rate, gamma_focal_loss)\n",
    "\n",
    "    # If the model has already been trained, return it\n",
    "    if best_CORAL_state_dict is not None:\n",
    "        return best_CORAL_state_dict, best_acc\n",
    "    \n",
    "    # Define the data loaders accounting for the batch size\n",
    "    gen_train_loader = get_loader(set_type=\"Generated\", set_name=\"train\", batch_size=batch_size // 2, balance=True)\n",
    "    gen_val_loader = get_loader(set_type=\"Generated\", set_name=\"validation\", batch_size=batch_size // 2, balance=True)\n",
    "    \n",
    "    real_train_loader = get_loader(set_type=\"Real\", set_name=\"train\", batch_size=batch_size // 2, balance=True)\n",
    "    real_val_loader = get_loader(set_type=\"Real\", set_name=\"validation\", batch_size=batch_size // 2, balance=True)\n",
    "\n",
    "    # Define the new loss function (Taking into account gamma)\n",
    "    focal_loss = torch.hub.load(\n",
    "        'adeelh/pytorch-multi-class-focal-loss',\n",
    "        model='FocalLoss',\n",
    "        gamma=gamma_focal_loss, # No use of alpha since we have balanced classes now with the oversampling\n",
    "        reduction='mean',\n",
    "        force_reload=False,\n",
    "        verbose = False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # To store the training metrics every iteration\n",
    "    training_total_losses = []\n",
    "    training_CORAL_losses = []\n",
    "    gen_training_classification_losses = []\n",
    "    gen_training_accs = []\n",
    "    gen_training_f1s = []\n",
    "\n",
    "    # To store the validation metrics every n_validation iterations\n",
    "    gen_validation_accs = []\n",
    "    gen_validation_f1s = []\n",
    "    real_validation_accs = []\n",
    "    real_validation_f1s = []\n",
    "    gen_validation_classification_losses = []\n",
    "    real_validation_classification_losses = []\n",
    "    validation_CORAL_losses = []\n",
    "    validation_total_losses_using_gen_classification_loss = []\n",
    "\n",
    "    # To store the validation accuracies every epoch\n",
    "    real_validation_accs_full = []\n",
    "\n",
    "    # Define the model and the optimizer\n",
    "    coralmodel = CoralModel().to(DEVICE)\n",
    "    opt = optim.Adam(coralmodel.parameters(), lr=learning_rate)\n",
    "\n",
    "    # To keep track of the best model (Best epoch)\n",
    "    best_real_acc = -1\n",
    "    best_model_state_dict = None\n",
    "    best_epoch = -1\n",
    "\n",
    "    # Compute the average accuracy on the validation set at epoch 0\n",
    "    average_acc = evaluate_epoch(coralmodel, real_val_loader)\n",
    "    real_validation_accs_full.append(average_acc)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train the model\n",
    "        for iteration, ((X_train_gen, y_train_gen), (X_train_real, _)) in tqdm(enumerate(zip(gen_train_loader, real_train_loader))):\n",
    "            \n",
    "            # Set the model to training mode\n",
    "            coralmodel.train()\n",
    "\n",
    "            # Linear progress of the training (from 0 to 1)\n",
    "            p = (epoch / num_epochs + iteration / len(real_train_loader) / num_epochs)\n",
    "            lamb = lambda_max_DA * p\n",
    "\n",
    "            # Move the data to the device\n",
    "            X_train_gen = X_train_gen.to(DEVICE)\n",
    "            y_train_gen = y_train_gen.to(DEVICE)\n",
    "            X_train_real = X_train_real.to(DEVICE)\n",
    "\n",
    "            # Forward pass for source data (Generated data)\n",
    "            hidden_rep_gen, y_train_pred_raw_gen = coralmodel(X_train_gen)\n",
    "            y_train_pred_gen = torch.argmax(y_train_pred_raw_gen, dim=1)\n",
    "\n",
    "            # Forward pass for target data (Real data)\n",
    "            hidden_rep_real, y_train_pred_raw_real = coralmodel(X_train_real)\n",
    "\n",
    "            # Compute the classification loss (Focal loss)\n",
    "            gen_classification_loss_train = focal_loss(y_train_pred_raw_gen, y_train_gen.long())\n",
    "\n",
    "            # Compute the domain loss (CORAL loss)\n",
    "            coral_loss_train = (CORAL_loss(hidden_rep_gen, hidden_rep_real) + CORAL_loss(y_train_pred_raw_gen, y_train_pred_raw_real))\n",
    "\n",
    "            # Get the total loss\n",
    "            total_train_loss = gen_classification_loss_train + lamb * coral_loss_train\n",
    "\n",
    "            # Compute the accuracy\n",
    "            gen_acc_train = accuracy(y_train_pred_gen, y_train_gen)\n",
    "            gen_f1_train = f1_score(y_train_pred_gen, y_train_gen)\n",
    "\n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            total_train_loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # Store the training metrics\n",
    "            training_total_losses.append(total_train_loss.item())\n",
    "            training_CORAL_losses.append(coral_loss_train.item())\n",
    "            gen_training_classification_losses.append(gen_classification_loss_train.item())\n",
    "            gen_training_accs.append(gen_acc_train.item())\n",
    "            gen_training_f1s.append(gen_f1_train.item())\n",
    "            \n",
    "            # Check if the model should be validated\n",
    "            if iteration == 0 or (iteration + 1) % n_validation == 0:\n",
    "                \n",
    "                # Set the model to evaluation mode\n",
    "                coralmodel.eval()\n",
    "                \n",
    "                # Disable gradient calculation\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    # Initialize variables\n",
    "                    gen_acc_val_sum = 0\n",
    "                    real_acc_val_sum = 0\n",
    "                    gen_weighted_f1_val_sum = 0\n",
    "                    real_weighted_f1_val_sum = 0\n",
    "                    gen_classification_loss_val_sum = 0\n",
    "                    real_classification_loss_val_sum = 0\n",
    "                    total_loss_val_sum = 0\n",
    "                    coral_loss_val_sum = 0\n",
    "\n",
    "                    # Extract an iterator from the data loaders\n",
    "                    gen_val_iter = iter(gen_val_loader)\n",
    "                    real_val_iter = iter(real_val_loader)\n",
    "\n",
    "                    # Iterate for n_validation_minibatches\n",
    "                    for _ in range(n_validation_minibatches):\n",
    "\n",
    "                        # Get the next minibatches\n",
    "                        minibatch = next(gen_val_iter, None)\n",
    "                        if minibatch is None:\n",
    "                            gen_val_iter = iter(gen_val_loader)\n",
    "                            minibatch = next(gen_val_iter, None)\n",
    "                        X_val_gen, y_val_gen = minibatch\n",
    "\n",
    "                        minibatch = next(real_val_iter, None)\n",
    "                        if minibatch is None:\n",
    "                            real_val_iter = iter(real_val_loader)\n",
    "                            minibatch = next(real_val_iter, None)\n",
    "                        X_val_real, y_val_real = minibatch\n",
    "                            \n",
    "                        # Move the data to the device\n",
    "                        X_val_gen = X_val_gen.to(DEVICE)\n",
    "                        y_val_gen = y_val_gen.to(DEVICE)\n",
    "                        X_val_real = X_val_real.to(DEVICE)\n",
    "                        y_val_real = y_val_real.to(DEVICE)\n",
    "\n",
    "                        # Forward pass for source data (Generated data)\n",
    "                        hidden_rep_gen, y_val_pred_raw_gen = coralmodel(X_val_gen)\n",
    "                        y_val_pred_gen = torch.argmax(y_val_pred_raw_gen, dim=1)\n",
    "\n",
    "                        # Forward pass for target data (Real data)\n",
    "                        hidden_rep_real, y_val_pred_raw_real = coralmodel(X_val_real)\n",
    "                        y_val_pred_real = torch.argmax(y_val_pred_raw_real, dim=1)\n",
    "\n",
    "                        # Compute the metrics\n",
    "                        gen_classification_loss_val_sum += focal_loss(y_val_pred_raw_gen, y_val_gen.long())\n",
    "                        real_classification_loss_val_sum += focal_loss(y_val_pred_raw_real, y_val_real.long())\n",
    "                        coral_loss_val_sum += (CORAL_loss(hidden_rep_gen, hidden_rep_real) + CORAL_loss(y_val_pred_raw_gen, y_val_pred_raw_real))\n",
    "                        total_loss_val_sum += gen_classification_loss_val_sum + lamb * coral_loss_val_sum # Only accounts for the generated classification loss as during training\n",
    "                        gen_acc_val_sum += accuracy(y_val_pred_gen, y_val_gen)\n",
    "                        real_acc_val_sum += accuracy(y_val_pred_real, y_val_real)\n",
    "                        gen_weighted_f1_val_sum += f1_score(y_val_pred_gen, y_val_gen)\n",
    "                        real_weighted_f1_val_sum += f1_score(y_val_pred_real, y_val_real)\n",
    "\n",
    "                    # Compute the average metrics\n",
    "                    gen_classification_loss_val = gen_classification_loss_val_sum / n_validation_minibatches\n",
    "                    real_classification_loss_val = real_classification_loss_val_sum / n_validation_minibatches\n",
    "                    coral_loss_val = coral_loss_val_sum / n_validation_minibatches\n",
    "                    total_loss_val = total_loss_val_sum / n_validation_minibatches\n",
    "                    gen_acc_val = gen_acc_val_sum / n_validation_minibatches\n",
    "                    real_acc_val = real_acc_val_sum / n_validation_minibatches\n",
    "                    gen_weighted_f1_val = gen_weighted_f1_val_sum / n_validation_minibatches\n",
    "                    real_weighted_f1_val = real_weighted_f1_val_sum / n_validation_minibatches\n",
    "\n",
    "                    # Store all metrics\n",
    "                    gen_validation_classification_losses.append(gen_classification_loss_val.item())\n",
    "                    real_validation_classification_losses.append(real_classification_loss_val.item())\n",
    "                    validation_CORAL_losses.append(coral_loss_val.item())\n",
    "                    validation_total_losses_using_gen_classification_loss.append(total_loss_val.item())\n",
    "                    gen_validation_accs.append(gen_acc_val.item())\n",
    "                    real_validation_accs.append(real_acc_val.item())\n",
    "                    gen_validation_f1s.append(gen_weighted_f1_val.item())\n",
    "                    real_validation_f1s.append(real_weighted_f1_val.item())\n",
    "\n",
    "                    # Print an update\n",
    "                    clear_output(wait=True) # Only show the last print statement\n",
    "                    print('----------------------------------------------------------------')\n",
    "                    print(f'TRAINING HP COMBINATION  [#{hyperparameter_combination_number}] -- EPOCH [{epoch+1}] --  ITERATION [{iteration+1}]')\n",
    "                    print(f'CURRENT BEST EPOCH: {best_epoch} -- CURRENT BEST FULL VALIDATION SET ACCURACY: {best_real_acc}')\n",
    "                    print('----------------------------------------------------------------')\n",
    "                    print(f'TRAINING => Total_loss: {total_train_loss} -- CORAL_loss: {coral_loss_train} -- Class_loss: {gen_classification_loss_train} -- Acc_gen: {gen_acc_train} -- F1_gen: {gen_f1_train}')\n",
    "                    print(f'GENERATED VALIDATION => Total_loss: {total_loss_val} -- Class_Loss: {gen_classification_loss_val} -- Acc_gen: {gen_acc_val} -- F1_gen: {gen_weighted_f1_val}')\n",
    "                    print(f'REAL VALIDATION => Class_loss: {real_classification_loss_val} -- Acc_real: {real_acc_val} -- F1_real: {real_weighted_f1_val}')\n",
    "                    print(f'SHARED VALIDATION => CORAL_loss: {coral_loss_val}')\n",
    "                    print('----------------------------------------------------------------')\n",
    "\n",
    "        # Save the model every epoch as a checkpoint \n",
    "        torch.save(coralmodel.state_dict(), f'./checkpoints/coralmodel_lr_{learning_rate}_lambdamax_{lambda_max_DA}_gamma_{gamma_focal_loss}_epoch_{epoch+1}.ckpt')\n",
    "\n",
    "        # Check whether the current epoch's model is the best yet\n",
    "\n",
    "        # Compute the average real validation accuracy of the epoch\n",
    "        average_real_acc = evaluate_epoch(coralmodel, real_val_loader)\n",
    "\n",
    "        # Append the average real validation accuracy of the epoch to the corresponding array\n",
    "        real_validation_accs_full.append(average_real_acc)\n",
    "\n",
    "        # Check whether the current version of the model is the best one\n",
    "        if best_model_state_dict is None or average_real_acc > best_real_acc:\n",
    "            best_real_acc = average_real_acc\n",
    "            best_model_state_dict = coralmodel.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # Plot and save the metrics\n",
    "    save_metrics_to_json(training_total_losses, training_CORAL_losses, gen_training_classification_losses,\\\n",
    "                        gen_training_accs, gen_training_f1s, gen_validation_accs, gen_validation_f1s, \\\n",
    "                        real_validation_accs, real_validation_f1s, validation_total_losses_using_gen_classification_loss, \\\n",
    "                        validation_CORAL_losses, gen_validation_classification_losses, real_validation_classification_losses, \\\n",
    "                        real_validation_accs_full, learning_rate, lambda_max_DA, gamma_focal_loss, batch_size, n_validation, \\\n",
    "                        n_validation_minibatches, num_epochs, best_real_acc, best_epoch)\n",
    "\n",
    "    return  best_model_state_dict, best_real_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e0fb873",
   "metadata": {},
   "source": [
    "We can now proceed to train and evaluate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db313a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1it [00:04,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "TRAINING HP COMBINATION  [#1] -- EPOCH [1] --  ITERATION [1]\n",
      "CURRENT BEST EPOCH: -1 -- CURRENT BEST FULL VALIDATION SET ACCURACY: -1\n",
      "----------------------------------------------------------------\n",
      "TRAINING => Total_loss: 2.1932382583618164 -- CORAL_loss: 9.109685095154418e-08 -- Class_loss: 2.1932382583618164 -- Acc_gen: 0.05999999865889549 -- F1_gen: 0.010666667483747005\n",
      "GENERATED VALIDATION => Total_loss: 4.219326972961426 -- Class_Loss: 2.1352365016937256 -- Acc_gen: 0.23999999463558197 -- F1_gen: 0.1740572452545166\n",
      "REAL VALIDATION => Class_loss: 2.1863954067230225 -- Acc_real: 0.14000000059604645 -- F1_real: 0.09348484873771667\n",
      "SHARED VALIDATION => CORAL_loss: 0.00011674200504785404\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:05,  2.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\Models\\CORAL\\CORAL.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m learning_rate \u001b[39min\u001b[39;00m learning_rate_choices:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m lambda_max_DA \u001b[39min\u001b[39;00m lambda_max_DA_choices:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         cur_best_model_state_dict, cur_best_real_acc \u001b[39m=\u001b[39m train(model_count, learning_rate, lambda_max_DA, gamma_focal_loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39m# Create a row to add to the dataframe\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         row \u001b[39m=\u001b[39m [lambda_max_DA, learning_rate, gamma_focal_loss, cur_best_real_acc]\n",
      "\u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\Models\\CORAL\\CORAL.ipynb Cell 35\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(hyperparameter_combination_number, learning_rate, lambda_max_DA, gamma_focal_loss, batch_size, n_validation, n_validation_minibatches, num_epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m real_validation_accs_full\u001b[39m.\u001b[39mappend(average_acc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mfor\u001b[39;00m iteration, ((X_train_gen, y_train_gen), (X_train_real, _)) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(gen_train_loader, real_train_loader))):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         \u001b[39m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         coralmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wassi/Documents/GitHub/RecogniChess/Models/CORAL/CORAL.ipynb#X54sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         \u001b[39m# Linear progress of the training (from 0 to 1)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\Models\\CORAL\\../../Datasets\\Custom_Dataset.py:84\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     82\u001b[0m     img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages[idx])\n\u001b[1;32m---> 84\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img_path)\n\u001b[0;32m     85\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n\u001b[0;32m     87\u001b[0m     \u001b[39m# Convert the label to int instead of float\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wassi\\Documents\\GitHub\\RecogniChess\\myenv\\lib\\site-packages\\PIL\\Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2950\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   2952\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 2953\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   2954\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2956\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# To store the best model\n",
    "best_real_acc = -1\n",
    "\n",
    "# Store the validation accuracies\n",
    "hp_final_accs = pd.DataFrame(columns=[\"Lambda max (DA factor)\", \"Learning Rate\",  \"Gamma (focal loss)\", \"Best Validation Accuracy\"])\n",
    "\n",
    "# To keep track of the number of models trained\n",
    "model_count = 1\n",
    "\n",
    "for gamma_focal_loss in gamma_focal_loss_choices:\n",
    "\n",
    "    for learning_rate in learning_rate_choices:\n",
    "\n",
    "        for lambda_max_DA in lambda_max_DA_choices:\n",
    "\n",
    "            # Train the model\n",
    "            cur_best_model_state_dict, cur_best_real_acc = train(model_count, learning_rate, lambda_max_DA, gamma_focal_loss)\n",
    "\n",
    "            # Create a row to add to the dataframe\n",
    "            row = [lambda_max_DA, learning_rate, gamma_focal_loss, cur_best_real_acc]\n",
    "\n",
    "            # Store it\n",
    "            hp_final_accs.loc[len(hp_final_accs)] = row\n",
    "\n",
    "            # Compare to the best model\n",
    "            if cur_best_real_acc > best_real_acc:\n",
    "                best_real_acc = cur_best_real_acc\n",
    "                torch.save(cur_best_model_state_dict, f'./best_CORAL_model.ckpt')\n",
    "\n",
    "            # Save (overwrite) the dataframe as a table every time a model finish training so that we can keep track of the progress\n",
    "            hp_final_accs.to_csv('./HP_best_real_accuracy_comparison_table.csv', index=False)\n",
    "\n",
    "            # Increment the model count\n",
    "            model_count += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64e5fcf3",
   "metadata": {},
   "source": [
    "After this code runs, the best model can be found in the directory of the script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
